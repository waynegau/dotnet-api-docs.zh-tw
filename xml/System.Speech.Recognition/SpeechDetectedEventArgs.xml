<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechDetectedEventArgs.xml" source-language="en-US" target-language="zh-TW">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5319a6fac2a70dc60263255b2ed9c3276379768f5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">319a6fac2a70dc60263255b2ed9c3276379768f5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>Returns data from <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" /&gt;</ph> or <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" /&gt;</ph> events.</source>
          <target state="translated">從 <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" /&gt;</ph> 或 <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" /&gt;</ph> 事件傳回資料。</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>A <ph id="ph1">`SpeechDetected`</ph> event is raised by the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> classes.</source>
          <target state="translated">A<ph id="ph1">`SpeechDetected`</ph>就會引發事件<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>和<ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>類別。</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source><bpt id="p1">**</bpt>SpeechDetected<ept id="p1">**</ept> events are generated when a recognition engine can identify audio input as human speech.</source>
          <target state="translated"><bpt id="p1">**</bpt>SpeechDetected<ept id="p1">**</ept>辨識引擎可以識別為人力語音音訊的輸入時，會產生事件。</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.EventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> 是衍生自 <ph id="ph2">&lt;xref:System.EventArgs&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>The example below creates a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> events.</source>
          <target state="translated">下列範例會建立的處理常式<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph>或<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph>事件。</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>The handler initializes a display every time speech is detected and displays status information, including audio position.</source>
          <target state="translated">此處理常式初始化顯示，每次偵測到語音，並顯示狀態資訊，包括音訊位置。</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>Gets the position in the audio stream where speech was detected.</source>
          <target state="translated">取得音訊資料流中偵測到語音的位置。</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>Returns the location of a detected phrase within a recognition engine’s speech buffer.</source>
          <target state="translated">傳回辨識引擎的語音緩衝區內偵測到片語的位置。</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>The example below creates a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> events.</source>
          <target state="translated">下列範例會建立的處理常式<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph>或<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph>事件。</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>The handler initializes a display each time speech is detected and displays status information, including audio position.</source>
          <target state="translated">此處理常式，初始化每個時間語音偵測到並顯示狀態資訊，包括音訊位置顯示。</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>